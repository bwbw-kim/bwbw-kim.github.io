---
title: ♻ Locust 로 우리 플랫폼 LoadTest 해보기
date: 2023-11-06
categories: [Python]
tags: [loadtest, locust, python]
render_with_liquid: true
---
#### LoadTest with Python Locust
---
우리 시스템에 로드 테스트를 해보고 싶었다. 실제로 우리 시스템이 몇개의 cpu 그리고 몇GB 의 RAM 을 가지고
몇명의 사람을 버티는지 알고 싶었고 그것을 알 수 있는 가장 빠른 python package 가 있었다. 바로 Locust 이다!
ngrinder, SoapUI 등등 다양한 툴이 있었지만 Locust 는 정말 단 시작한지 3분만에 load test 환경이 구축이 되어
빠르게 진행 할 수 있었다.

```bash
pip install locust
```

이 한줄이면 우선 설치가 가능했다! locust 를 설치한 다음에는 `locustfile.py` 을 작성해 준다.

```python
from locust import HttpUser, task, between, TaskSet

class LoadTest(TaskSet):

    @task
    def get_main_page(self):
        self.client.get('/')

class LocustUser(HttpUser):
    host = "https://our.platform.com"
    tasks = [LoadTest]
    wait_time = between(1, 4) # 한 유저가 request 하고 1~4초 뒤에 다시 request 하는 것을 의미한다.
```

이미 코드에서도 느껴지겠지만 이 load test 는 메인페이지를 공략하는 것이다! 이렇게 하나하는것 이외에도

```
@task(weight=1)
def task_one(self):
    ...

@task(weight=2)
def task_two(self):
    ..
```

weight 를 줘서 1 : 2 의 비율로 요청하게 만들 수 도 있다. 아무튼 `locustfile.py` 이 완성을 해준다.

#### Locustfile 실행하기
---
이것도 정말 간단하다 바로 아래처럼 실행해주면 사이트가 하나 뜬다.

```bash
locust -f locustfile.py
```

사이트가 뜨면 빈칸을 채워준다.

| Number of users | Spawn rate                                                                        | Host                                             |
| --------------- | --------------------------------------------------------------------------------- | ------------------------------------------------ |
| 최대 유저수     | 한번에 유저가 생성되는 수 (한번에 max 로 테스트하는것은 바람직 하지 않다고 한다!) | 아까 locustfile 에 적은 https://our.platform.com |

#### RPS, RT 가 뭘까?
---
그리고 실행하면 loadtest 가 실행되며 그래프가 제공된다. 그래프에서 보여주는 값은 RPS, RT 가 있다.

RPS 는 초당 Request 수 이다. 한명의 User 는 요청을하고 응답을 받기까지 기다리고 응답을 받으면 wait_time 만큼 기다렸다가 다시 Request 하는 방식이다. 따라서 높을수록 많은 유저를 한번에 감당 할 수 있다는 소리이다!

RT 는 Response Time 이다. 한명의 User 가 요청을 하고 응답을 받기까지 걸리는 시간이다.! 따라서 낮을 수록 유저가 response 받는 시간이 빨라진다는 것이다!

User 가 막 늘어났을때 RPS 그리고 RT 이 두가지가 안정적으로 saturation 되면 안정적인 플랫폼이라고 할 수 있고

RPS 는 saturation 이 되었지만 RT 가 증가한다면 플랫폼에 병목이 있구나 라고 예측 할 수 있다

우리는 400 명의 user 를 가지고 RPS 그리고 RT(1초 안쪽) 안정적인 서비스 되기를 목표로 잡았다!
